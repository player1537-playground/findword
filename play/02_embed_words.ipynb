{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ebbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// script\n",
    "# dependencies = [\"fasttext-wheel\", \"numpy\", \"pandas\"]\n",
    "# ///\n",
    "\n",
    "\"\"\"\n",
    "Generate FastText embeddings for a list of words and save to CSV.\n",
    "\n",
    "This script reads words from a text file (one per line), generates embeddings\n",
    "using a pre-trained FastText model, and saves the results to a CSV file with\n",
    "word and embedding columns.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d389c7e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import fasttext\n",
    "except ImportError:\n",
    "    print(\"Error: fasttext-wheel package not found\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a5d5d7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_fasttext_model(model_dir: Path) -> fasttext.FastText._FastText:\n",
    "    \"\"\"\n",
    "    Load FastText model from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        model_dir: Path to directory containing .bin model file\n",
    "\n",
    "    Returns:\n",
    "        Loaded FastText model\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If no .bin file found in directory\n",
    "    \"\"\"\n",
    "    bin_files = list(model_dir.glob(\"*.bin\"))\n",
    "\n",
    "    if not bin_files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No .bin model file found in {model_dir}. \"\n",
    "            \"Please download a FastText model first.\"\n",
    "        )\n",
    "\n",
    "    model_path = bin_files[0]\n",
    "    print(f\"Loading FastText model from: {model_path}\")\n",
    "\n",
    "    model = fasttext.load_model(str(model_path))\n",
    "    print(f\"Model loaded successfully!\")\n",
    "    print(f\"Model vocabulary size: {len(model.words)}\")\n",
    "    print()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc5e44",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def read_words(input_file: Path) -> List[str]:\n",
    "    \"\"\"\n",
    "    Read words from input file, one word per line.\n",
    "\n",
    "    Args:\n",
    "        input_file: Path to input text file\n",
    "\n",
    "    Returns:\n",
    "        List of words (whitespace stripped)\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If input file doesn't exist\n",
    "    \"\"\"\n",
    "    if not input_file.exists():\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        words = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    print(f\"Read {len(words)} words from {input_file}\")\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c1201",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(\n",
    "    model: fasttext.FastText._FastText,\n",
    "    words: List[str]\n",
    ") -> List[Tuple[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Generate embeddings for a list of words with progress indication.\n",
    "\n",
    "    Args:\n",
    "        model: Loaded FastText model\n",
    "        words: List of words to embed\n",
    "\n",
    "    Returns:\n",
    "        List of (word, embedding) tuples\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    total = len(words)\n",
    "\n",
    "    print(f\"Generating embeddings for {total} words...\")\n",
    "\n",
    "    for i, word in enumerate(words, 1):\n",
    "        embedding = model.get_word_vector(word)\n",
    "        embeddings.append((word, embedding))\n",
    "\n",
    "        # Progress indication\n",
    "        if i % 100 == 0 or i == total:\n",
    "            print(f\"  Progress: {i}/{total} ({100*i/total:.1f}%)\")\n",
    "\n",
    "    print(f\"Generated {len(embeddings)} embeddings\")\n",
    "    print(f\"Embedding dimension: {len(embeddings[0][1])}\")\n",
    "    print()\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd706ee9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def save_embeddings(\n",
    "    embeddings: List[Tuple[str, np.ndarray]],\n",
    "    output_file: Path\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Save embeddings to CSV file.\n",
    "\n",
    "    Args:\n",
    "        embeddings: List of (word, embedding) tuples\n",
    "        output_file: Path to output CSV file\n",
    "    \"\"\"\n",
    "    # Convert embeddings to JSON arrays for CSV storage\n",
    "    data = {\n",
    "        'word': [word for word, _ in embeddings],\n",
    "        'embedding': [json.dumps(emb.tolist()) for _, emb in embeddings]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Create output directory if needed\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved embeddings to: {output_file}\")\n",
    "    print(f\"  Rows: {len(df)}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  File size: {output_file.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4686f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def parse_args() -> argparse.Namespace:\n",
    "    \"\"\"Parse command-line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Generate FastText embeddings for words from a text file\",\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        'input_file',\n",
    "        type=Path,\n",
    "        nargs='?',\n",
    "        default=Path('words.txt'),\n",
    "        help=\"Input text file with words (one per line)\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-o', '--output',\n",
    "        type=Path,\n",
    "        dest='output_file',\n",
    "        default=Path('embeddings.csv'),\n",
    "        help=\"Output CSV file for embeddings\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-m', '--model-dir',\n",
    "        type=Path,\n",
    "        dest='model_dir',\n",
    "        default=None,\n",
    "        help=\"Directory containing FastText .bin model (default: data/fasttext/)\"\n",
    "    )\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d58ad7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    args = parse_args()\n",
    "\n",
    "    # Determine model directory\n",
    "    if args.model_dir is None:\n",
    "        script_dir = Path(__file__).parent\n",
    "        project_root = script_dir.parent\n",
    "        model_dir = project_root / \"data\" / \"fasttext\"\n",
    "    else:\n",
    "        model_dir = args.model_dir\n",
    "\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"FastText Word Embedding Generator\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Input file: {args.input_file}\")\n",
    "    print(f\"Output file: {args.output_file}\")\n",
    "    print(f\"Model directory: {model_dir}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    try:\n",
    "        # Load model\n",
    "        model = load_fasttext_model(model_dir)\n",
    "\n",
    "        # Read words\n",
    "        words = read_words(args.input_file)\n",
    "\n",
    "        # Generate embeddings\n",
    "        embeddings = generate_embeddings(model, words)\n",
    "\n",
    "        # Save to CSV\n",
    "        save_embeddings(embeddings, args.output_file)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Embedding generation completed successfully!\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\", file=sys.stderr)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46839f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env -S uv run --isolated --no-project --script",
   "formats": "py:percent,ipynb",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
