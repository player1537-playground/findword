{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bde2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// script\n",
    "# dependencies = [\"fasttext-wheel\", \"numpy\", \"scikit-learn\", \"matplotlib\", \"pandas\"]\n",
    "# ///\n",
    "\n",
    "\"\"\"\n",
    "Visualize word embeddings using t-SNE dimensionality reduction.\n",
    "\n",
    "This script reads words from a text file, generates FastText embeddings,\n",
    "applies PCA and t-SNE for dimensionality reduction, and creates a 2D\n",
    "scatter plot visualization with word labels.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b302c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "try:\n",
    "    import fasttext\n",
    "except ImportError:\n",
    "    print(\"Error: fasttext-wheel package not found\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf2e6b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_fasttext_model(model_dir: Path) -> fasttext.FastText._FastText:\n",
    "    \"\"\"\n",
    "    Load FastText model from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        model_dir: Path to directory containing .bin model file\n",
    "\n",
    "    Returns:\n",
    "        Loaded FastText model\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If no .bin file found in directory\n",
    "    \"\"\"\n",
    "    bin_files = list(model_dir.glob(\"*.bin\"))\n",
    "\n",
    "    if not bin_files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No .bin model file found in {model_dir}. \"\n",
    "            \"Please download a FastText model first.\"\n",
    "        )\n",
    "\n",
    "    model_path = bin_files[0]\n",
    "    print(f\"Loading FastText model from: {model_path}\")\n",
    "\n",
    "    model = fasttext.load_model(str(model_path))\n",
    "    print(f\"Model loaded successfully!\")\n",
    "    print(f\"Model vocabulary size: {len(model.words)}\")\n",
    "    print()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3cfb73",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def read_words(input_file: Path, line_limit: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Read words from input file with optional line limit.\n",
    "\n",
    "    Args:\n",
    "        input_file: Path to input text file\n",
    "        line_limit: Maximum number of words to read (0 = no limit)\n",
    "\n",
    "    Returns:\n",
    "        List of words (whitespace stripped)\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If input file doesn't exist\n",
    "    \"\"\"\n",
    "    if not input_file.exists():\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "\n",
    "    words = []\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if line_limit > 0 and i >= line_limit:\n",
    "                break\n",
    "            word = line.strip()\n",
    "            if word:\n",
    "                words.append(word)\n",
    "\n",
    "    print(f\"Read {len(words)} words from {input_file}\")\n",
    "    if line_limit > 0:\n",
    "        print(f\"  (limited to first {line_limit} lines)\")\n",
    "    print()\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d72ce",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(\n",
    "    model: fasttext.FastText._FastText,\n",
    "    words: List[str]\n",
    ") -> Tuple[List[str], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate embeddings for a list of words.\n",
    "\n",
    "    Args:\n",
    "        model: Loaded FastText model\n",
    "        words: List of words to embed\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (words, embeddings_matrix)\n",
    "    \"\"\"\n",
    "    print(f\"Generating embeddings for {len(words)} words...\")\n",
    "\n",
    "    embeddings = []\n",
    "    for word in words:\n",
    "        embedding = model.get_word_vector(word)\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    embeddings_matrix = np.array(embeddings)\n",
    "\n",
    "    print(f\"Generated embeddings matrix:\")\n",
    "    print(f\"  Shape: {embeddings_matrix.shape}\")\n",
    "    print(f\"  Dimensions: {embeddings_matrix.shape[1]}\")\n",
    "    print(f\"  Number of words: {embeddings_matrix.shape[0]}\")\n",
    "    print()\n",
    "\n",
    "    return words, embeddings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29706912",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def reduce_dimensions(embeddings: np.ndarray, n_components: int = 8) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply PCA to reduce embedding dimensions.\n",
    "\n",
    "    Args:\n",
    "        embeddings: Original embeddings matrix\n",
    "        n_components: Target number of dimensions\n",
    "\n",
    "    Returns:\n",
    "        Reduced embeddings matrix\n",
    "    \"\"\"\n",
    "    print(f\"Applying PCA to reduce dimensions...\")\n",
    "    print(f\"  Original dimensions: {embeddings.shape[1]}\")\n",
    "    print(f\"  Target dimensions: {n_components}\")\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced = pca.fit_transform(embeddings)\n",
    "\n",
    "    variance_explained = pca.explained_variance_ratio_.sum()\n",
    "    print(f\"  Reduced dimensions: {reduced.shape[1]}\")\n",
    "    print(f\"  Variance explained: {variance_explained:.2%}\")\n",
    "    print()\n",
    "\n",
    "    return reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed010e3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def apply_tsne(embeddings: np.ndarray, perplexity: int = 30) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply t-SNE for 2D visualization.\n",
    "\n",
    "    Args:\n",
    "        embeddings: Input embeddings matrix\n",
    "        perplexity: t-SNE perplexity parameter\n",
    "\n",
    "    Returns:\n",
    "        2D coordinates for visualization\n",
    "    \"\"\"\n",
    "    print(f\"Applying t-SNE for 2D visualization...\")\n",
    "    print(f\"  Input dimensions: {embeddings.shape[1]}\")\n",
    "    print(f\"  Number of samples: {embeddings.shape[0]}\")\n",
    "    print(f\"  Perplexity: {perplexity}\")\n",
    "\n",
    "    # Adjust perplexity if necessary\n",
    "    max_perplexity = (embeddings.shape[0] - 1) // 3\n",
    "    if perplexity > max_perplexity:\n",
    "        perplexity = max_perplexity\n",
    "        print(f\"  Adjusted perplexity to: {perplexity}\")\n",
    "\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=perplexity,\n",
    "        random_state=42,\n",
    "        n_iter=1000\n",
    "    )\n",
    "    coords_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "    print(f\"  Output dimensions: {coords_2d.shape[1]}\")\n",
    "    print(f\"  Final shape: {coords_2d.shape}\")\n",
    "    print()\n",
    "\n",
    "    return coords_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b681de",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_visualization(\n",
    "    words: List[str],\n",
    "    coords_2d: np.ndarray,\n",
    "    output_file: Path\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create and save scatter plot visualization.\n",
    "\n",
    "    Args:\n",
    "        words: List of words\n",
    "        coords_2d: 2D coordinates for each word\n",
    "        output_file: Path to save the visualization\n",
    "    \"\"\"\n",
    "    print(f\"Creating visualization...\")\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    # Scatter plot\n",
    "    plt.scatter(coords_2d[:, 0], coords_2d[:, 1], alpha=0.6, s=100)\n",
    "\n",
    "    # Add word labels\n",
    "    for i, word in enumerate(words):\n",
    "        plt.annotate(\n",
    "            word,\n",
    "            xy=(coords_2d[i, 0], coords_2d[i, 1]),\n",
    "            xytext=(5, 2),\n",
    "            textcoords='offset points',\n",
    "            fontsize=9,\n",
    "            alpha=0.8\n",
    "        )\n",
    "\n",
    "    plt.title(\n",
    "        f't-SNE Visualization of FastText Word Embeddings\\n({len(words)} words)',\n",
    "        fontsize=14,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "    plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "    plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Create output directory if needed\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved visualization to: {output_file}\")\n",
    "    print(f\"  Format: {output_file.suffix}\")\n",
    "    print(f\"  File size: {output_file.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09efd8f3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def parse_args() -> argparse.Namespace:\n",
    "    \"\"\"Parse command-line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Visualize word embeddings using t-SNE\",\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        'input_file',\n",
    "        type=Path,\n",
    "        nargs='?',\n",
    "        default=Path('words.txt'),\n",
    "        help=\"Input text file with words (one per line)\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-l', '--line-limit',\n",
    "        type=int,\n",
    "        dest='line_limit',\n",
    "        default=100,\n",
    "        help=\"Maximum number of words to visualize (0 = no limit)\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-o', '--output',\n",
    "        type=Path,\n",
    "        dest='output_image',\n",
    "        default=Path('tsne_visualization.png'),\n",
    "        help=\"Output image file path\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-m', '--model-dir',\n",
    "        type=Path,\n",
    "        dest='model_dir',\n",
    "        default=None,\n",
    "        help=\"Directory containing FastText .bin model (default: data/fasttext/)\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-p', '--perplexity',\n",
    "        type=int,\n",
    "        default=30,\n",
    "        help=\"t-SNE perplexity parameter\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--pca-dims',\n",
    "        type=int,\n",
    "        default=8,\n",
    "        dest='pca_dims',\n",
    "        help=\"Number of PCA dimensions before t-SNE\"\n",
    "    )\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c5dce",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    args = parse_args()\n",
    "\n",
    "    # Determine model directory\n",
    "    if args.model_dir is None:\n",
    "        script_dir = Path(__file__).parent\n",
    "        project_root = script_dir.parent\n",
    "        model_dir = project_root / \"data\" / \"fasttext\"\n",
    "    else:\n",
    "        model_dir = args.model_dir\n",
    "\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"FastText Word Embedding t-SNE Visualization\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Input file: {args.input_file}\")\n",
    "    print(f\"Line limit: {args.line_limit if args.line_limit > 0 else 'No limit'}\")\n",
    "    print(f\"Output image: {args.output_image}\")\n",
    "    print(f\"Model directory: {model_dir}\")\n",
    "    print(f\"PCA dimensions: {args.pca_dims}\")\n",
    "    print(f\"t-SNE perplexity: {args.perplexity}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    try:\n",
    "        # Load model\n",
    "        model = load_fasttext_model(model_dir)\n",
    "\n",
    "        # Read words\n",
    "        words = read_words(args.input_file, args.line_limit)\n",
    "\n",
    "        if len(words) == 0:\n",
    "            print(\"Error: No words found in input file\", file=sys.stderr)\n",
    "            sys.exit(1)\n",
    "\n",
    "        if len(words) < 3:\n",
    "            print(\"Error: Need at least 3 words for visualization\", file=sys.stderr)\n",
    "            sys.exit(1)\n",
    "\n",
    "        # Generate embeddings\n",
    "        words, embeddings = generate_embeddings(model, words)\n",
    "\n",
    "        # Reduce dimensions with PCA\n",
    "        embeddings_pca = reduce_dimensions(embeddings, args.pca_dims)\n",
    "\n",
    "        # Apply t-SNE\n",
    "        coords_2d = apply_tsne(embeddings_pca, args.perplexity)\n",
    "\n",
    "        # Create visualization\n",
    "        create_visualization(words, coords_2d, args.output_image)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Visualization completed successfully!\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\", file=sys.stderr)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d824748",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env -S uv run --isolated --no-project --script",
   "formats": "py:percent,ipynb",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
